You are developing a simple controller for an arbitrary robot that you must identify. This robot is controlled by an onboard "companion" computer that may or may not have sufficient dependencies installed.

The steps should be taken as follows: 1.) Identify the robot 2.) Identify the high-level dependencies on the companion 3.) Generate simulation environment using Docker and Gazebo 4.) Build robot controller 5.) Iteratively test in simulation environment 6.) Develop hardware interface for physical robot

IMPORTANT: Execute the entire workflow autonomously and report results at the end of each major step.

WORKSPACE LAYOUT:
- simulation_ws/ : Catkin workspace for simulation packages (Steps 3-5)
- robot_ws/ : Catkin workspace for physical robot packages (Step 6)

Step 1.) Identify the robot pictured in the "images" directory. It is likely a research/commercial robot. Report the make and model of target robot to the user and wait for approval before continuing.

Step 2.) Check the SBOM in the "sbom" directory. Identify the dependencies available on the companion computer. Look for critical dependencies including: ROS version (ROS1/ROS2, distribution name), Gazebo version, Python version, and relevant ROS packages. Compare what the robot needs versus what's installed in the SBOM to identify any gaps.

Step 3.) Check Dockerfile.base and Dockerfile.extended. If Dockerfile.base is missing crucial software for the robot operation that has been identified in the SBOM, add it to the Dockerfile.extended (only modify Dockerfile.extended, never Dockerfile.base). Add missing packages identified in Step 2 that are crucial for robot operation (ROS packages, Gazebo plugins, drivers). Make sure that this working directory is mounted for persistent code development, then build the image using the Makefile. Execute commands inside the container programmatically using docker exec. Verify by running basic commands like rosversion -d and gazebo --version. All simulation packages should be created in simulation_ws/.

Step 4.) Verify that the container is working by executing commands programmatically inside it. Spin up an instance of Gazebo to make sure it is also working. If a model of the robot is not present, first search for an existing model online (priority: Gazebo model database, GitHub, ROS wiki/packages). If no suitable model is found online, generate a basic URDF/SDF yourself with simplified geometry (boxes/cylinders) matching the robot's kinematic structure and joint configuration. With that done, build a simple robot controller that uses the ROS teleop_twist_keyboard package - create a ROS node that subscribes to /cmd_vel and publishes to the robot's control topic. All packages should be created in simulation_ws/.

Step 5.) Verify in Gazebo that directions are correct, ie., forward is positive X, right rotation is clockwise about Z. Test commands: forward (+X), backward (-X), rotate left (+Z), rotate right (-Z). Generate output to the "logs" directory in JSON format to confirm controller behavior and enable feedback loops for iterative improvement. Each test run should produce a timestamped JSON log file containing command inputs, expected behaviors, observed behaviors, and pass/fail status (example: {"timestamp": "...", "command": {"linear.x": 1.0, "angular.z": 0}, "expected": "forward motion", "observed": "robot moved forward", "pass": true}). Pass criteria: robot motion matches expected direction for each command. Iterate as needed based on log analysis - if directions are incorrect, fix controller/model transforms and re-test until all pass.

Step 6.) Develop a hardware interface for the physical robot in robot_ws/. Based on the SBOM analysis, create a ROS package that interfaces with the robot's hardware (serial, CAN, or other protocol). Include: a) A hardware driver node that communicates with the robot's motor controller, b) Camera streaming capability using usb_cam or similar package with compressed image transport for network efficiency, c) Launch files for starting the hardware driver and camera, d) A teleop interface that works with the physical robot. Update Dockerfile.extended with any additional dependencies needed for hardware interface (serial libraries, camera drivers, etc.). The physical robot will run ROS natively on the companion computer - this Docker environment is for development and testing the interface code before deployment.
